# ==============================================================================
#  Julia Script: Overlapping Liquidity Baskets (AMO Model)
# ==============================================================================

using Dynare
using CSV
using DataFrames
using Statistics
using Printf 

MOD_FILENAME = "AMO_model.mod"
OUTPUT_FOLDER = "output"

# --- GLOBAL VARIABLE INITIALIZATION ---

ALL_VARS = String[]
ALL_SHOCKS = String[] 

# ==============================================================================
#  SECTION 1: CONFIGURATION
# ==============================================================================

# A. SIMULATION & IRF SETTINGS
SIM_PERIODS = 1000   
BURN_IN     = 100    
# INCREASED HORIZON: To ensure variance decomposition is accurate (captures full decay)
IRF_HORIZON = 100    

# B. BASKET MAPPING (Binary: 1 = Asset in Basket)
MARKET_MAP = [
    1 1 1 0 0 ;  # Basket 1
    0 0 1 1 1    # Basket 2
]

# *** MONETARY POLICY CONFIGURATION ***
# Format: (Asset_Increase_Supply, Asset_Decrease_Supply)
MP_PAIRS = [
    (1, 3) 
]

# C. PARAMETERS
GLOBAL_PARAMS = Dict(
    # --- Consumer Preferences ---
    "beta"   => 0.99,   # Discount factor
    "sigma"  => 2.0,    # Risk aversion
    "gamma"  => 2.0,    # Liquidity curvature
    
    # --- Liquidity Parameters ---
    "psi"    => 0.5,    # Liquidity weight
    "eta"    => 1.5,    # Substitution across groups
    
    # --- Endowment ---
    "y"      => 1.0,    
    
    # --- Shock Process Parameters ---
    "rho_G"  => 0.9,    
    "sig_G"  => 0.01,   
    "rho_a"  => 0.9,    
    "sig_a"  => 0.01,   
    
    # *** Monetary Policy Parameters ***
    "rho_mp" => 0.9,    # Persistence
    "sig_mp" => 0.05    # Volatility 
)

BASKET_RHO     = [10.0, 2.0]
BASKET_DELTA   = [0.2, 0.8]
BASKET_WEIGHTS = [0.5, 0.5]

ASSET_SUPPLY_BAR = [2.0, 2.0, 1.0, 0.5, 0.5] 
ASSET_PHI        = [0.1, 0.1, 0.2, 1.5, 1.5] 
ASSET_DELTA_IDIO = [0.1, 0.1, 0.5, 0.9, 0.9] 

# ==============================================================================
#  SECTION 2: GENERATION LOGIC
# ==============================================================================

N_BASKETS, N_ASSETS = size(MARKET_MAP)
N_MP_PAIRS = length(MP_PAIRS)
BASKET_ALPHA_BAR = BASKET_WEIGHTS ./ sum(BASKET_WEIGHTS)

# Reset lists
empty!(ALL_VARS)
empty!(ALL_SHOCKS)

open(MOD_FILENAME, "w") do io
    println("Generating $MOD_FILENAME...")
    
    global ALL_VARS, ALL_SHOCKS

    # A. VARIABLES
    write(io, "// Generated by Julia\nvar L c\n")
    push!(ALL_VARS, "L", "c")
    
    for i in 1:N_ASSETS
        write(io, "    omega_G_$i omega_a_$i\n")
        push!(ALL_VARS, "omega_G_$i", "omega_a_$i")
    end
    
    # MP Shock Variables
    for p in 1:N_MP_PAIRS
        write(io, "    omega_mp_$p\n")
        push!(ALL_VARS, "omega_mp_$p")
    end

    for k in 1:N_BASKETS
        write(io, "    L_k$k alpha_k$k omega_a_basket_$k\n")
        push!(ALL_VARS, "L_k$k", "alpha_k$k", "omega_a_basket_$k")
    end
    for i in 1:N_ASSETS
        write(io, "    R_$i\n")
        push!(ALL_VARS, "R_$i")
    end
    for k in 1:N_BASKETS
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1
                write(io, "    b_$(i)_k$(k) alpha_$(i)_k$(k)\n")
                push!(ALL_VARS, "b_$(i)_k$(k)", "alpha_$(i)_k$(k)")
            end
        end
    end
    
    write(io, ";\n\nvarexo\n")
    # Supply Shocks
    for i in 1:N_ASSETS
        write(io, "    eps_G_$i eps_a_$i\n")
        push!(ALL_SHOCKS, "eps_G_$i", "eps_a_$i")
    end
    # Basket Shocks
    for k in 1:N_BASKETS
        write(io, "    eps_a_basket_$k\n")
        push!(ALL_SHOCKS, "eps_a_basket_$k")
    end
    # MP Shocks
    for p in 1:N_MP_PAIRS
        write(io, "    eps_mp_$p\n")
        push!(ALL_SHOCKS, "eps_mp_$p")
    end

    write(io, ";\n\nparameters\n")
    
    # B. PARAMETERS & CALIBRATION
    for (k,v) in GLOBAL_PARAMS; write(io, "    $k\n"); end
    for k in 1:N_BASKETS; write(io, "    rho_k$k alpha_bar_k$k delta_k$k\n"); end
    for i in 1:N_ASSETS;  write(io, "    b_bar_$i phi_$i delta_idio_$i\n"); end
    for k in 1:N_BASKETS
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1; write(io, "    alpha_bar_$(i)_k$(k)\n"); end
        end
    end
    write(io, ";\n\n// CALIBRATION\n")
    for (k,v) in GLOBAL_PARAMS; write(io, "$k = $v;\n"); end
    for k in 1:N_BASKETS
        write(io, "rho_k$k = $(BASKET_RHO[k]); alpha_bar_k$k = $(BASKET_ALPHA_BAR[k]); delta_k$k = $(BASKET_DELTA[k]);\n")
    end
    for i in 1:N_ASSETS
        write(io, "b_bar_$i = $(ASSET_SUPPLY_BAR[i]); phi_$i = $(ASSET_PHI[i]); delta_idio_$i = $(ASSET_DELTA_IDIO[i]);\n")
    end
    for k in 1:N_BASKETS
        n_in = sum(MARKET_MAP[k,:])
        w_val = 1.0 / n_in
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1; write(io, "alpha_bar_$(i)_k$(k) = $w_val;\n"); end
        end
    end

    # C. MODEL BLOCK
    write(io, "\nmodel;\n    c = y;\n")
    for i in 1:N_ASSETS
        write(io, "    omega_G_$i = rho_G * omega_G_$i(-1) + sig_G * eps_G_$i;\n")
        write(io, "    omega_a_$i = rho_a * omega_a_$i(-1) + sig_a * eps_a_$i;\n")
    end
    for k in 1:N_BASKETS
        write(io, "    omega_a_basket_$k = rho_a * omega_a_basket_$k(-1) + sig_a * eps_a_basket_$k;\n")
    end

    for p in 1:N_MP_PAIRS
        write(io, "    omega_mp_$p = rho_mp * omega_mp_$p(-1) + sig_mp * eps_mp_$p;\n")
    end
    
    terms_L = ["(alpha_k$k * L_k$k^((eta-1)/eta))" for k in 1:N_BASKETS]
    write(io, "    L = ( " * join(terms_L, " + ") * " )^(eta/(eta-1));\n")

    for k in 1:N_BASKETS
        terms_Lk = []
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1; push!(terms_Lk, "(alpha_$(i)_k$(k) * b_$(i)_k$(k)^((rho_k$k-1)/rho_k$k))"); end
        end
        write(io, "    L_k$k = ( " * join(terms_Lk, " + ") * " )^(rho_k$k/(rho_k$k-1));\n")
    end

    denom_k_str = join(["(alpha_bar_k$j * exp(delta_k$j * omega_a_basket_$j))" for j in 1:N_BASKETS], " + ")
    for k in 1:N_BASKETS
        write(io, "    alpha_k$k = (alpha_bar_k$k * exp(delta_k$k * omega_a_basket_$k)) / ($denom_k_str);\n")
    end

    for k in 1:N_BASKETS
        denom_ik_str = join(["(alpha_bar_$(j)_k$(k) * exp(delta_idio_$j * omega_a_$j))" for j in 1:N_ASSETS if MARKET_MAP[k,j]==1], " + ")
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1
                num = "(alpha_bar_$(i)_k$(k) * exp(delta_idio_$i * omega_a_$i))"
                write(io, "    alpha_$(i)_k$(k) = $num / ($denom_ik_str);\n")
            end
        end
    end

    # Market Clearing with MP Shocks
    for i in 1:N_ASSETS
        lhs = "b_bar_$i + phi_$i * omega_G_$i"
        mp_terms_list = String[]
        for p in 1:N_MP_PAIRS
            u, v = MP_PAIRS[p]
            if i == u
                push!(mp_terms_list, "+ omega_mp_$p")
            elseif i == v
                push!(mp_terms_list, "- omega_mp_$p")
            end
        end
        
        if !isempty(mp_terms_list)
            lhs = lhs * " " * join(mp_terms_list, " ")
        end

        rhs = join(["b_$(i)_k$(k)" for k in 1:N_BASKETS if MARKET_MAP[k,i]==1], " + ")
        write(io, "    $lhs = $rhs;\n")
    end

    for k in 1:N_BASKETS
        for i in 1:N_ASSETS
            if MARKET_MAP[k,i] == 1
                lhs = "1 - beta * R_$i"
                rhs = "(psi / c^(-sigma)) * (alpha_k$k * alpha_$(i)_k$(k)) * L^(1/eta - gamma) * L_k$k^(1/rho_k$k - 1/eta) * b_$(i)_k$(k)^(-1/rho_k$k)"
                write(io, "    $lhs = $rhs;\n")
            end
        end
    end
    write(io, "end;\n\n")

    # D. INIT & SOLVE
    write(io, "initval;\n    c = y; L = 1.0;\n")
    for i in 1:N_ASSETS;  write(io, "    omega_G_$i = 0; omega_a_$i = 0;\n"); end
    for k in 1:N_BASKETS; write(io, "    omega_a_basket_$k = 0;\n"); end
    for p in 1:N_MP_PAIRS; write(io, "    omega_mp_$p = 0;\n"); end

    for i in 1:N_ASSETS
        share = ASSET_SUPPLY_BAR[i] / sum(MARKET_MAP[:,i])
        write(io, "    R_$i = 1.0/beta - 0.005;\n")
        for k in 1:N_BASKETS
            if MARKET_MAP[k,i] == 1
                write(io, "    b_$(i)_k$(k) = $share; alpha_$(i)_k$(k) = $(1.0/sum(MARKET_MAP[k,:]));\n")
            end
        end
    end
    for k in 1:N_BASKETS; write(io, "    L_k$k = 1.0; alpha_k$k = $(BASKET_ALPHA_BAR[k]);\n"); end
    write(io, "end;\n\n")

    write(io, "shocks;\n")
    for i in 1:N_ASSETS;  write(io, "    var eps_G_$i = 1; var eps_a_$i = 1;\n"); end
    for k in 1:N_BASKETS; write(io, "    var eps_a_basket_$k = 1;\n"); end
    for p in 1:N_MP_PAIRS; write(io, "    var eps_mp_$p = 1;\n"); end
    write(io, "end;\n\nsteady;\ncheck;\n")
    write(io, "stoch_simul(order=1, drop=$BURN_IN, periods=$SIM_PERIODS, irf=$IRF_HORIZON, graph_format=pdf);\n")
end
println("Success! Created $MOD_FILENAME")

# ==============================================================================
#  SECTION 3: EXECUTION & POST-PROCESSING
# ==============================================================================

println("\n--- Running Dynare ---")
global context = @dynare "AMO_model.mod"
if !isdir(OUTPUT_FOLDER); mkdir(OUTPUT_FOLDER); end

# --- PART A: PANEL IRF EXPORT ---
println("\n--- Exporting IRFs ---")
try
    local model_res = context.results.model_results[1]
    local irf_dict  = model_res.irfs
    local df_panel = DataFrame(Period=Int[], Variable=String[], Shock=String[], Value=Float64[])
    
    for (dict_key, dict_val) in irf_dict
        local shock_name = string(dict_key)
        local data_mat   = Matrix(dict_val) 
        local col_names  = (hasproperty(dict_val, :names)) ? string.(dict_val.names) : string.(propertynames(dict_val))

        for (i, var_name) in enumerate(col_names)
            if i > size(data_mat, 2); continue; end
            local values_vec = data_mat[:, i]
            local n_obs = length(values_vec)
            append!(df_panel, DataFrame("Period"=>1:n_obs, "Variable"=>fill(var_name, n_obs), "Shock"=>fill(shock_name, n_obs), "Value"=>values_vec))
        end
    end
    CSV.write(joinpath(OUTPUT_FOLDER, "IRFs_Panel_Data.csv"), df_panel)
catch e
    println("❌ Error building panel IRFs: $e")
end

# --- PART B: VARIANCE DECOMPOSITION (Calculated from IRFs) ---
println("\n--- Calculating Variance Decomposition (from IRFs) ---")
try
    
    
    local irf_dict = context.results.model_results[1].irfs
    local decomp_dict = Dict{String, Dict{String, Float64}}() # Map: Asset -> Shock -> SumSq
    
    # 1. Iterate through all shocks
    for (shock_key, shock_val) in irf_dict
        local shock_name = string(shock_key)
        local col_names = (hasproperty(shock_val, :names)) ? string.(shock_val.names) : string.(propertynames(shock_val))
        local data_mat = Matrix(shock_val)
        
        for (i, var_name) in enumerate(col_names)
            if !haskey(decomp_dict, var_name)
                decomp_dict[var_name] = Dict{String, Float64}()
            end
        # Check if everrythign all right
        last_val = data_mat[end, i]
        if abs(last_val) > 1e-4
        println("⚠️ Warning: IRF for $var_name to $shock_name has not decayed to zero (Val: $last_val). Decomposition may be biased.")
        end

local sum_sq = sum(data_mat[:, i] .^ 2)
            # Calculate Sum of Squared Impulse Responses
            
            local sum_sq = sum(data_mat[:, i] .^ 2)
            decomp_dict[var_name][shock_name] = sum_sq
        end
    end
    
    # 2. Build DataFrame & Calculate Shares
    local df_vardecomp = DataFrame(Asset=String[], Shock=String[], Variance_Share=Float64[])
    
    for var_name in keys(decomp_dict)
        # Only process Returns (R_*) for cleanliness, or all vars
        if !occursin(r"R_\d+", var_name); continue; end
        
        local total_var = sum(values(decomp_dict[var_name]))
        if total_var < 1e-12; continue; end # Avoid division by zero for constants
        
        for (shock_name, sq_val) in decomp_dict[var_name]
            local share = (sq_val / total_var) * 100.0
            push!(df_vardecomp, (var_name, shock_name, share))
        end
    end
    
    CSV.write(joinpath(OUTPUT_FOLDER, "Variance_Decomposition.csv"), df_vardecomp)
    println("✔ Saved calculated decomposition to Variance_Decomposition.csv")

    # 3. Calibration View (Summary)
    println("\n--- CALIBRATION VIEW: Return Variance Explained by Shock Type ---")
    println("(Adjust 'sig_mp' in Config to target specific MP importance)\n")
    
    local df_agg = copy(df_vardecomp)
    df_agg.Shock_Type = [
        occursin("eps_mp", s) ? "Monetary Policy" : 
        occursin("eps_G", s) ? "Supply" : "Preferences" 
        for s in df_agg.Shock
    ]
    
    local gdf = groupby(df_agg, [:Asset, :Shock_Type])
    local df_summary = combine(gdf, :Variance_Share => sum => :Total_Share)
    
    println(rpad("Asset", 10) * rpad("Shock Type", 20) * "Variance Explained (%)")
    println("-"^55)
    
    sort!(df_summary, [:Asset, :Shock_Type])
    
    for row in eachrow(df_summary)
        @printf("%-10s %-20s %6.2f%%\n", row.Asset, row.Shock_Type, row.Total_Share)
    end
    
    CSV.write(joinpath(OUTPUT_FOLDER, "Calibration_Summary.csv"), df_summary)

catch e
    println("❌ Variance Decomposition failed: $e")
end

# --- PART C: SIMULATION EXPORT ---
println("\n--- Exporting Simulation Data ---")
try
    local raw_data = hasproperty(context.results, :endo_simul) ? context.results.endo_simul : Matrix(context.results.model_results[1].simulations[1].data)
    local sim_data = (size(raw_data,1) < size(raw_data,2)) ? raw_data' : raw_data
    local headers = (size(sim_data, 2) == length(ALL_VARS)) ? ALL_VARS : ["Var$i" for i in 1:size(sim_data, 2)]
    CSV.write(joinpath(OUTPUT_FOLDER, "Simulation_Cleaned.csv"), DataFrame(sim_data, headers))
catch e
    println("❌ Simulation Export failed: $e")
end

println("\n✔ DONE.")